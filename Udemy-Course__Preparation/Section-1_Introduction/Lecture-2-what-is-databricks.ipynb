{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2. What is Databricks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Databricks \n",
    "  \n",
    "  * Multi-cloud Lakehouse Platform based on Apache Spark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Lakehouse\n",
    "\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"../../assets/images/what is lakehouse.jpg\" style=\"width:800px\" >\n",
    "  </div>\n",
    "\n",
    "  A *data lakehouse* is a unified analytics platform that combines the best elements of data lakes and data warehouses, deliver \n",
    "  - the openness, flexibility and machine learning support of data lakes with \n",
    "  - the reliability, strong governance and performance of data warehouses.\n",
    "  \n",
    "  So in the lake house you work on that engineering, analytics and AI all in one platform.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of Databricks Lakehouse\n",
    "  \n",
    "  It is divided into three important layers: the cloud service, the runtime and the workspace.\n",
    "\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"../../assets/images/Architecture of Databricks Lakehouse.jpg\" style=\"width:400px\" >\n",
    "  </div>\n",
    "\n",
    "  * First, the **cloud service**: Databricks is multi-cloud, available on Microsoft Azure, Amazon Web Services and Google Cloud.\n",
    "\n",
    "  * Then there is the Databricks **runtime**, which is a set of core components like Apache Spark, Delta Lake and other system libraries. We will see Delta Lake in detail in the next module. \n",
    "    \n",
    "    Databricks uses the infrastructure of your cloud provider to provision virtual machines or nodes of a cluster. And this cluster comes pre-installed with Databricks runtime. \n",
    "\n",
    "  * On top of all this, there is the Databricks **workspace** allowing you to interactively implement and run your data engineering, analytics and AI workloads.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Databricks resources are deployed in your cloud provider\n",
    "\n",
    "  There are two high level components: the control plan and the data plan.\n",
    "\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"../../assets/images/the control plan and the data plan.jpg\" style=\"width:400px\" >\n",
    "  </div>\n",
    "\n",
    "  * The control plan resides in Databricks account while the data plan is in your own cloud subscription.\n",
    "\n",
    "  * Whenever you create a databricks workspace, it is deployed in the **control plan** along with Databricks services like Databricks UI, Cluster Manager, workflow service and notebooks.\n",
    "\n",
    "  * On the other hand, a storage account is deployed in the **data plan** in your own subscription. It is used for Databricks File System or DBFS. In addition, when you want to set up a spark cluster, the cluster virtual machine will be also deployed in the data plan. So to summarize, the compute and the storage will be always in your own cloud account.\n",
    "\n",
    "  Databricks will provide you with the tools you need to use and control your infrastructure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark on Databricks\n",
    "\n",
    "  Databricks has been founded by the same engineers that developed Spark because it is based on Apache Spark.\n",
    "\n",
    "  * The data is distributed and processed in-memory of multiple nodes in a cluster.\n",
    "\n",
    "  * Databricks supports all the languages supported by Spark which are Scala, Python, SQL, R and Java as well.\n",
    "\n",
    "  * It has also support for batch processing and stream processing in Spark.\n",
    "\n",
    "  * In addition, on Databricks, you can process data no matter if it is structured, semi-structured, or even unstructured like assets/images and videos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databricks File System (DBFS)\n",
    "\n",
    "  Since Apache Spark processes data in a distributed manner, \n",
    "  Databricks offers a native support of a distributed file system called *Databricks File System* or *DBFS*. \n",
    "  So whenever you create a cluster in Databricks, it comes pre-installed with DBFS.\n",
    "\n",
    "  We usually use file systems to persist data and files. \n",
    "  However, DBFS is just an abstraction layer, \n",
    "  while it uses the underlying cloud storage to persist the data.\n",
    "\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"../../assets/images/DBFS uses the underlying cloud storage.jpg\" style=\"width:400px\" >\n",
    "  </div>\n",
    "\n",
    "  To illustrate this, if you create a file in your cluster and store it in DBFS, \n",
    "  this file is actually persisted in the underlying cloud storage, \n",
    "  like your Azure storage or your S3 buckets.\n",
    "  So even after the cluster is terminated, all the data is safe in your cloud storage.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
