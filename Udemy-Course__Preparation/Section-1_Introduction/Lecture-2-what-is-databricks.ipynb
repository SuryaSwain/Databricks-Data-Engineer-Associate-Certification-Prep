{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2. What is Databricks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference  \n",
    "- [Databricks Glossary - Data Lakehouse](https://www.databricks.com/glossary/data-lakehouse)\n",
    "- [Documentation > What is Databricks? > Databricks architecture overview](https://docs.databricks.com/getting-started/overview.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Databricks \n",
    "  \n",
    "  * Multi-cloud Lakehouse Platform based on Apache Spark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Lakehouse\n",
    "\n",
    "  A ***data lakehouse*** is a unified analytics platform that combines the best elements of **data lakes** and **data warehouses**.\n",
    "\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"../../assets/images/Presentation-Images/what is lakehouse.jpg\" style=\"width:800px\" >\n",
    "  </div>\n",
    "\n",
    "  Data lakehouse delivers\n",
    "  - the openness, flexibility and machine learning support of data lakes with \n",
    "  - the reliability, strong governance and performance of data warehouses.\n",
    "  \n",
    "  So in the lake house you work on that engineering, analytics and AI all in one platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of Databricks Lakehouse\n",
    "  \n",
    "It is divided into three important **layers**: the cloud service, the runtime and the workspace.\n",
    "\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"../../assets/images/Presentation-Images/Architecture of Databricks Lakehouse.jpg\" style=\"width:400px\" >\n",
    "  </div>\n",
    "\n",
    "* First, the ***cloud service***: Databricks is multi-cloud, available on Microsoft Azure, Amazon Web Services and Google Cloud.\n",
    "\n",
    "* Then there is the Databricks ***runtime***, which is a set of core components like Apache Spark, Delta Lake and other system libraries. We will see Delta Lake in detail in the next module. \n",
    "  \n",
    "  Databricks uses the infrastructure of your cloud provider to provision virtual machines or nodes of a **cluster**. And this cluster comes pre-installed with Databricks runtime. \n",
    "\n",
    "* On top of all this, there is the Databricks ***workspace*** allowing you to interactively implement and run your data engineering, analytics and AI workloads.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Databricks resources are deployed in your cloud provider\n",
    "\n",
    "  There are two high level components: the control plane and the data plane.\n",
    "  The ***control plane*** resides in **Databricks account** while the ***data plane*** is in your own **cloud subscription**.\n",
    "\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"../../assets/images/Presentation-Images/the control plan and the data plan.jpg\" style=\"width:400px\" >\n",
    "  </div>\n",
    "\n",
    "\n",
    "  * Whenever you create a **databricks workspace**, it is deployed in the **control plane** along with Databricks services like **Databricks UI**, **Cluster Manager**, **workflow service** and **notebooks**.\n",
    "\n",
    "  * On the other hand, a **storage account** is deployed in the **data plane** in your own subscription. It is used for *Databricks File System* or *DBFS*. In addition, when you want to set up a **spark cluster**, the cluster virtual machine will be also deployed in the data plan. So to summarize, the compute and the storage will be always in your own cloud account.\n",
    "\n",
    "  **Databricks will provide you with the tools you need to use and control your infrastructure.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark on Databricks\n",
    "\n",
    "Databricks has been founded by the same engineers that developed Spark because it is based on Apache Spark.\n",
    "\n",
    "  * The data is **distributed** and **processed in-memory** of multiple nodes in a cluster.\n",
    "\n",
    "  * Databricks supports **all the languages supported by Spark**, which are Scala, Python, SQL, R and Java as well.\n",
    "\n",
    "  * It has also support for **batch processing and stream processing in Spark**.\n",
    "\n",
    "  * In addition, on Databricks, you can process **all types of data** no matter if it is structured, semi-structured, or even unstructured like assets/images and videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databricks File System (DBFS)\n",
    "\n",
    "Since Apache Spark processes data in a distributed manner, \n",
    "Databricks offers a native support of a *distributed file system* called ***Databricks File System*** or ***DBFS***. \n",
    "So whenever you create a *cluster* in Databricks, it comes pre-installed with DBFS.\n",
    "\n",
    "We usually use file systems to persist data and files. \n",
    "However, DBFS is just an *abstraction layer*, \n",
    "while it uses the underlying cloud storage to persist the data.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../../assets/images/Presentation-Images/DBFS uses the underlying cloud storage.jpg\" style=\"width:400px\" >\n",
    "</div>\n",
    "\n",
    "To illustrate this, if you create a file in your cluster and store it in DBFS, \n",
    "this file is actually persisted in the underlying cloud storage, \n",
    "like your Azure storage or your S3 buckets.\n",
    "So even after the cluster is terminated, all the data is safe in your cloud storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Complemental Notes](../../complemental-notes/CompNotes-for-Lecture-2.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
